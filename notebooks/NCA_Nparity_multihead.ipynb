{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heysoos\\anaconda3\\envs\\torchstuff\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.9.15)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "from skimage.color import rgba2rgb\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "from math import *\n",
    "import time\n",
    "\n",
    "from os import makedirs, path\n",
    "from copy import deepcopy\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# brush properties\n",
    "r = 5\n",
    "s = 1\n",
    "\n",
    "def LMB_make(state, r=5, s=1):\n",
    "    '''\n",
    "    left click to make\n",
    "    r: radius of brush\n",
    "    s: smoothing / sigma\n",
    "    '''\n",
    "    xcl, ycl = pygame.mouse.get_pos()\n",
    "    xcl, ycl = int(xcl/UPSCALE), int(ycl/UPSCALE)\n",
    "\n",
    "    # radial blur\n",
    "    xm, ym = torch.meshgrid(torch.linspace(-1, 1, 2*r), torch.linspace(-1, 1, 2*r))\n",
    "    rm = torch.sqrt(xm**2 + ym**2).type(torch.double)\n",
    "    blur = torch.exp(-rm**2 / s**2)\n",
    "    blur = torch.where(rm <= 1., blur, 0.) # circular mask\n",
    "\n",
    "    xslice = range(xcl - r, xcl + r)\n",
    "    yslice = range(ycl - r, ycl + r)\n",
    "    for count_i, i in enumerate(xslice):\n",
    "        for count_j, j in enumerate(yslice):\n",
    "            i = i % RESX\n",
    "            j = j % RESY\n",
    "            state[:, 1, i, j] = state[:, 1, i, j] + 5.\n",
    "    return state\n",
    "\n",
    "\n",
    "def RMB_del(state, r=5, s=1):\n",
    "    '''\n",
    "    right click to erase\n",
    "    r: radius of eraser\n",
    "    s: smoothing / sigma\n",
    "    '''\n",
    "    xcl, ycl = pygame.mouse.get_pos()\n",
    "    xcl, ycl = int(xcl/UPSCALE), int(ycl/UPSCALE)\n",
    "\n",
    "    # radial blur\n",
    "    xm, ym = torch.meshgrid(torch.linspace(-1, 1, 2*r), torch.linspace(-1, 1, 2*r))\n",
    "    rm = torch.sqrt(xm**2 + ym**2).type(torch.double)\n",
    "    blur = (1 - torch.exp(-rm**2 / s**2))\n",
    "    blur = torch.where(rm <= 1., blur, 1.) # circular mask\n",
    "\n",
    "    xslice = range(xcl - r, xcl + r)\n",
    "    yslice = range(ycl - r, ycl + r)\n",
    "    for count_i, i in enumerate(xslice):\n",
    "        for count_j, j in enumerate(yslice):\n",
    "            i = i % RESX\n",
    "            j = j % RESY\n",
    "            state[:, 1, i, j] = state[:, 1, i, j] - 0.2\n",
    "    return state\n",
    "\n",
    "def print_something(something):\n",
    "    fps = f'{something:.3f}'\n",
    "    fps_text = font.render(fps, 1, pygame.Color(\"white\"))\n",
    "    fps_bg = pygame.Surface((fps_text.get_height(),fps_text.get_width()))  # the size of your rect\n",
    "    fps_bg.set_alpha(50)                # alpha level\n",
    "    fps_bg.fill((255,255,255))           # this fills the entire surface\n",
    "\n",
    "    fps_surf = pygame.Surface((fps_bg.get_height(), fps_bg.get_width()))\n",
    "    fps_surf.blit(fps_bg, (0, 0))\n",
    "    fps_surf.blit(fps_text, (0, 0))\n",
    "    return fps_surf\n",
    "\n",
    "def plot_classification_scores(class_scores, correct_classes, width=100, height=400):\n",
    "    num_samples = class_scores.shape[0]\n",
    "    BAR_WIDTH = width\n",
    "    BAR_HEIGHT = int( 0.8 * height / (4 * num_samples))\n",
    "    BAR_SPACING = BAR_HEIGHT // 2\n",
    "    BAR_Y_OFFSET = int(0.1 * height)\n",
    "\n",
    "    CLASS_SPACING = 3*BAR_HEIGHT\n",
    "\n",
    "    # Create a surface for drawing the graph\n",
    "    graph_surface = pygame.Surface((width, height), pygame.SRCALPHA)\n",
    "    graph_surface.fill((255, 255, 255, 63))  # Fill with transparent color\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        score1 = class_scores[i][0]\n",
    "        score2 = class_scores[i][1]\n",
    "        correct_class = correct_classes[i]\n",
    "\n",
    "        # # Normalize scores to fit in the graph\n",
    "        # score1 = max(min(score1, 1), -1)  # Clamp scores to be within [-1, 1]\n",
    "        # score2 = max(min(score2, 1), -1)\n",
    "\n",
    "        # Draw the bars\n",
    "        predicted = np.argmax([score1, score2])\n",
    "        bar_colors = np.zeros((2, 3))\n",
    "        GREEN = np.array([0, 255, 0])\n",
    "        RED = np.array([255, 0, 0])\n",
    "\n",
    "        if predicted == correct_class:\n",
    "            # Highlight the correct class\n",
    "            bar_colors[predicted] = GREEN\n",
    "        else:\n",
    "            bar_colors[predicted] = RED\n",
    "\n",
    "        # Draw left bar\n",
    "        # rect(left, top, width, height)\n",
    "        bar1_top = i * (2 * BAR_HEIGHT + CLASS_SPACING) + BAR_Y_OFFSET\n",
    "        bar1_width = int(score1 * BAR_WIDTH)\n",
    "        pygame.draw.rect(graph_surface, bar_colors[0], (0, bar1_top, bar1_width, BAR_HEIGHT))\n",
    "\n",
    "        # Draw right bar\n",
    "        # bar2_top = (i + 1) * BAR_HEIGHT + i * CLASS_SPACING + BAR_SPACING + BAR_Y_OFFSET\n",
    "        bar2_top = bar1_top + BAR_HEIGHT + BAR_SPACING\n",
    "        bar2_width = int(score2 * BAR_WIDTH)\n",
    "        pygame.draw.rect(graph_surface, bar_colors[1], (0, bar2_top, bar2_width, BAR_HEIGHT))\n",
    "\n",
    "        # Add text label\n",
    "        text = font.render(f'N={i + 2}', True, (0, 0, 0))\n",
    "        text_rect = text.get_rect(center=(width//2, int(bar1_top-0.5*BAR_Y_OFFSET)))\n",
    "        graph_surface.blit(text, text_rect)\n",
    "\n",
    "    return graph_surface\n",
    "\n",
    "def WHEEL_permute(cdim_order, direction):\n",
    "    cdim_order = np.mod(np.add(cdim_order, direction), len(cdim_order))\n",
    "\n",
    "    return cdim_order\n",
    "\n",
    "def min_max(mat):\n",
    "    return (mat - mat.min()) / (mat.max() - mat.min())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class Rule(nn.Module):\n",
    "    def __init__(self,\n",
    "                 CHANNELS=8,\n",
    "                 FILTERS=1,\n",
    "                 NET_SIZE=[16],\n",
    "                 RES=50,\n",
    "                 READIN_CHANNELS=1,\n",
    "                 READOUT_CHANNELS=1,\n",
    "                 READIN_SCALE=1,\n",
    "                 READOUT_SCALE=1,\n",
    "                 NUM_READOUT_HEADS=10):\n",
    "        super().__init__()\n",
    "        self.channels = CHANNELS\n",
    "        self.filters = FILTERS\n",
    "        self.net_size = NET_SIZE\n",
    "        self.alpha = torch.nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "        self.rin_channels = READIN_CHANNELS\n",
    "        self.rout_channels = READOUT_CHANNELS\n",
    "        self.rin_scale = READIN_SCALE\n",
    "        self.rout_scale = READOUT_SCALE\n",
    "\n",
    "        # for forward_perception\n",
    "        self.ident = torch.tensor([[0.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 0.0]]).cuda()\n",
    "        self.sobel_x = torch.tensor([[-1.0, 0.0, 1.0], [-2.0, 0.0, 2.0], [-1.0, 0.0, 1.0]]).cuda() / 8.0\n",
    "        self.lap = torch.tensor([[1.0, 2.0, 1.0], [2.0, -12, 2.0], [1.0, 2.0, 1.0]]).cuda() / 16.0\n",
    "\n",
    "        self.filters = [nn.Parameter(torch.randn(3, 3).cuda())\n",
    "                        for i in range(FILTERS)]\n",
    "\n",
    "        self.ws = [torch.nn.Conv2d(CHANNELS * (4 + FILTERS), NET_SIZE[0], 1)]\n",
    "        self.ws += [torch.nn.Conv2d(NET_SIZE[i], NET_SIZE[i + 1], 1) for i in range(len(NET_SIZE) - 1)]\n",
    "        self.ws += [torch.nn.Conv2d(NET_SIZE[-1], CHANNELS, 1)]\n",
    "\n",
    "\n",
    "        # self.w1 = torch.nn.Conv2d(CHANNELS * (4 + FILTERS), HIDDEN, 1)\n",
    "        # self.w1.bias.data.zero_()\n",
    "        # self.w2 = torch.nn.Conv2d(HIDDEN, HIDDEN, 1)\n",
    "        # self.w3 = torch.nn.Conv2d(HIDDEN, CHANNELS, 1)\n",
    "\n",
    "        # read in layer is used to project from 1D -> CA grid via 3 input channels\n",
    "        # readout layer is used to project from CA grid via 3 output channels -> num_classes (2)\n",
    "        readin_res = int(READIN_SCALE*RES)\n",
    "        readout_res = int(READOUT_SCALE*RES)\n",
    "        self.readin = torch.nn.Linear(1, int(readin_res*readin_res*READIN_CHANNELS))\n",
    "        self.readouts = [torch.nn.Linear(int(readout_res*readout_res*READOUT_CHANNELS), 2, bias=True).cuda() for i in range(NUM_READOUT_HEADS)]\n",
    "\n",
    "        self.module_list = torch.nn.ModuleList(self.ws + self.readouts)\n",
    "        self.parameter_list = torch.nn.ParameterList(self.filters)\n",
    "        # self.w2.weight.data.zero_()\n",
    "        ###########################################\n",
    "\n",
    "class CA(nn.Module):\n",
    "    def __init__(self,\n",
    "                 CHANNELS=8,\n",
    "                 FILTERS=1,\n",
    "                 NET_SIZE=[16],\n",
    "                 RES=50,\n",
    "                 READIN_CHANNELS=1,\n",
    "                 READOUT_CHANNELS=1,\n",
    "                 READIN_SCALE=1,\n",
    "                 READOUT_SCALE=1,\n",
    "                 NUM_READOUT_HEADS=10):\n",
    "        super().__init__()\n",
    "        self.channels = CHANNELS\n",
    "        self.filters = FILTERS\n",
    "        self.net_size = NET_SIZE\n",
    "        self.res = RES\n",
    "\n",
    "\n",
    "        self.rule = Rule(CHANNELS, FILTERS, NET_SIZE, RES, READIN_CHANNELS, READOUT_CHANNELS, READIN_SCALE, READOUT_SCALE, NUM_READOUT_HEADS)\n",
    "\n",
    "    def initGrid(self, BS):\n",
    "        grid = torch.cuda.FloatTensor(2 * np.random.rand(BS, self.channels, self.res, self.res) - 1)\n",
    "        # first channel is input channel\n",
    "        # grid[:, -1, ...] *= 0.\n",
    "        return grid * 0.\n",
    "\n",
    "    def seed(self, RES, n):\n",
    "        seed = torch.randn(n, self.channels, RES, RES)\n",
    "        return seed\n",
    "\n",
    "    def perchannel_conv(self, x, filters):\n",
    "        '''filters: [filter_n, h, w]'''\n",
    "        b, ch, h, w = x.shape\n",
    "        y = x.reshape(b * ch, 1, h, w)\n",
    "        y = torch.nn.functional.pad(y, [1, 1, 1, 1], 'circular')\n",
    "        y = torch.nn.functional.conv2d(y, filters[:, None])\n",
    "        return y.reshape(b, -1, h, w)\n",
    "\n",
    "    def perception(self, x):\n",
    "        filters = [self.rule.ident, self.rule.sobel_x, self.rule.sobel_x.T, self.rule.lap]\n",
    "        filters = filters + self.rule.filters\n",
    "        return self.perchannel_conv(x, torch.stack(filters))\n",
    "\n",
    "    def get_living_mask(self, x, alive_thres=0):\n",
    "        alpha_channel = x[:, 0:1, :, :]\n",
    "        R = 1\n",
    "        d = 2*R+1\n",
    "        alpha_channel = F.pad(alpha_channel, (R, R, R, R), mode='circular')\n",
    "\n",
    "        alive_mask = F.max_pool2d(alpha_channel, kernel_size=d, stride=1, padding=R).abs() > alive_thres\n",
    "        alive_mask = alive_mask[:, :, R:-R, R:-R]\n",
    "\n",
    "        return alive_mask\n",
    "\n",
    "    def forward(self, x, dt=1, update_rate=1.):\n",
    "        b, ch, h, w = x.shape\n",
    "        pre_mask = self.get_living_mask(x)\n",
    "        y = self.perception(x)\n",
    "\n",
    "        for layer_i in self.rule.ws[:-1]:\n",
    "            y = F.leaky_relu(layer_i(y))\n",
    "        y = self.rule.ws[-1](y)\n",
    "        # y = self.rule.w3(y)\n",
    "\n",
    "\n",
    "        update_mask = (torch.rand(b, 1, h, w) + update_rate).floor().cuda()\n",
    "        y = dt * y * update_mask\n",
    "        y = y * pre_mask\n",
    "        # y = dt * y\n",
    "        # keep the first channel empty for inputs\n",
    "        # y[:, -1, ...] *= 0.\n",
    "        # res = torch.clamp(x + y, 0, 1)\n",
    "        alpha = torch.sigmoid(self.rule.alpha)\n",
    "        res = (1 - alpha) * x + alpha * y\n",
    "        post_mask = self.get_living_mask(res)\n",
    "        res = res*post_mask\n",
    "        # res = F.leaky_relu(x + y)\n",
    "        return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's train the model now in the N-Parity task. We will project the 1-D timeseries in 3 of the 8 channel dimensions of all the cells in the grid (size=1 x RESxRESx3). We will then read out from 3 different channels from the entire grid to get a classification (size=RESxRESx3 x 1)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def generate_binary_sequence(M):\n",
    "    return (torch.rand(M) < 0.5) * 2. - 1.\n",
    "\n",
    "def make_batch_Nbit_pair_parity(Ns, M, bs):\n",
    "    with torch.no_grad():\n",
    "        sequences = [generate_binary_sequence(M).unsqueeze(-1) for i in range(bs)]\n",
    "        labels = [torch.stack([get_parity(s, N) for s in sequences]) for N in Ns]\n",
    "\n",
    "    return torch.stack(sequences), labels\n",
    "\n",
    "def get_parity(vec, N):\n",
    "    return  (((vec + 1)/2)[-N:].sum() % 2).long()\n",
    "\n",
    "def pad_to(mat, shape_to):\n",
    "    shape = mat.shape\n",
    "    # shape diff\n",
    "    shd = [shape_to[0]-shape[2], shape_to[1]-shape[3]]\n",
    "    pad = [shd[0]//2, shd[0]//2, shd[1]//2, shd[1]//2]\n",
    "    return F.pad(mat, pad, mode='constant')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "CHANNELS=3\n",
    "FILTERS=0\n",
    "NET_SIZE=[16]\n",
    "NUM_READOUT_HEADS=100\n",
    "\n",
    "READIN_CHANNELS = 1\n",
    "READIN_SCALE = 1\n",
    "READOUT_CHANNELS = 1\n",
    "READOUT_SCALE = 1\n",
    "\n",
    "RES = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = 'cuda'\n",
    "ca = CA(CHANNELS=CHANNELS,\n",
    "        FILTERS=FILTERS,\n",
    "        NET_SIZE=NET_SIZE,\n",
    "        RES=RES,\n",
    "        READIN_CHANNELS=READIN_CHANNELS,\n",
    "        READOUT_CHANNELS=READOUT_CHANNELS,\n",
    "        READIN_SCALE=READIN_SCALE,\n",
    "        READOUT_SCALE=READOUT_SCALE,\n",
    "        NUM_READOUT_HEADS=NUM_READOUT_HEADS,\n",
    "        ).to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rule.alpha               1\n",
      "rule.readin.weight     400\n",
      "rule.readin.bias       400\n",
      "rule.module_list.0.weight   192\n",
      "rule.module_list.0.bias    16\n",
      "rule.module_list.1.weight    48\n",
      "rule.module_list.1.bias     3\n",
      "rule.module_list.2.weight   800\n",
      "rule.module_list.2.bias     2\n",
      "rule.module_list.3.weight   800\n",
      "rule.module_list.3.bias     2\n",
      "rule.module_list.4.weight   800\n",
      "rule.module_list.4.bias     2\n",
      "rule.module_list.5.weight   800\n",
      "rule.module_list.5.bias     2\n",
      "rule.module_list.6.weight   800\n",
      "rule.module_list.6.bias     2\n",
      "rule.module_list.7.weight   800\n",
      "rule.module_list.7.bias     2\n",
      "rule.module_list.8.weight   800\n",
      "rule.module_list.8.bias     2\n",
      "rule.module_list.9.weight   800\n",
      "rule.module_list.9.bias     2\n",
      "rule.module_list.10.weight   800\n",
      "rule.module_list.10.bias     2\n",
      "rule.module_list.11.weight   800\n",
      "rule.module_list.11.bias     2\n",
      "rule.module_list.12.weight   800\n",
      "rule.module_list.12.bias     2\n",
      "rule.module_list.13.weight   800\n",
      "rule.module_list.13.bias     2\n",
      "rule.module_list.14.weight   800\n",
      "rule.module_list.14.bias     2\n",
      "rule.module_list.15.weight   800\n",
      "rule.module_list.15.bias     2\n",
      "rule.module_list.16.weight   800\n",
      "rule.module_list.16.bias     2\n",
      "rule.module_list.17.weight   800\n",
      "rule.module_list.17.bias     2\n",
      "rule.module_list.18.weight   800\n",
      "rule.module_list.18.bias     2\n",
      "rule.module_list.19.weight   800\n",
      "rule.module_list.19.bias     2\n",
      "rule.module_list.20.weight   800\n",
      "rule.module_list.20.bias     2\n",
      "rule.module_list.21.weight   800\n",
      "rule.module_list.21.bias     2\n",
      "rule.module_list.22.weight   800\n",
      "rule.module_list.22.bias     2\n",
      "rule.module_list.23.weight   800\n",
      "rule.module_list.23.bias     2\n",
      "rule.module_list.24.weight   800\n",
      "rule.module_list.24.bias     2\n",
      "rule.module_list.25.weight   800\n",
      "rule.module_list.25.bias     2\n",
      "rule.module_list.26.weight   800\n",
      "rule.module_list.26.bias     2\n",
      "rule.module_list.27.weight   800\n",
      "rule.module_list.27.bias     2\n",
      "rule.module_list.28.weight   800\n",
      "rule.module_list.28.bias     2\n",
      "rule.module_list.29.weight   800\n",
      "rule.module_list.29.bias     2\n",
      "rule.module_list.30.weight   800\n",
      "rule.module_list.30.bias     2\n",
      "rule.module_list.31.weight   800\n",
      "rule.module_list.31.bias     2\n",
      "rule.module_list.32.weight   800\n",
      "rule.module_list.32.bias     2\n",
      "rule.module_list.33.weight   800\n",
      "rule.module_list.33.bias     2\n",
      "rule.module_list.34.weight   800\n",
      "rule.module_list.34.bias     2\n",
      "rule.module_list.35.weight   800\n",
      "rule.module_list.35.bias     2\n",
      "rule.module_list.36.weight   800\n",
      "rule.module_list.36.bias     2\n",
      "rule.module_list.37.weight   800\n",
      "rule.module_list.37.bias     2\n",
      "rule.module_list.38.weight   800\n",
      "rule.module_list.38.bias     2\n",
      "rule.module_list.39.weight   800\n",
      "rule.module_list.39.bias     2\n",
      "rule.module_list.40.weight   800\n",
      "rule.module_list.40.bias     2\n",
      "rule.module_list.41.weight   800\n",
      "rule.module_list.41.bias     2\n",
      "rule.module_list.42.weight   800\n",
      "rule.module_list.42.bias     2\n",
      "rule.module_list.43.weight   800\n",
      "rule.module_list.43.bias     2\n",
      "rule.module_list.44.weight   800\n",
      "rule.module_list.44.bias     2\n",
      "rule.module_list.45.weight   800\n",
      "rule.module_list.45.bias     2\n",
      "rule.module_list.46.weight   800\n",
      "rule.module_list.46.bias     2\n",
      "rule.module_list.47.weight   800\n",
      "rule.module_list.47.bias     2\n",
      "rule.module_list.48.weight   800\n",
      "rule.module_list.48.bias     2\n",
      "rule.module_list.49.weight   800\n",
      "rule.module_list.49.bias     2\n",
      "rule.module_list.50.weight   800\n",
      "rule.module_list.50.bias     2\n",
      "rule.module_list.51.weight   800\n",
      "rule.module_list.51.bias     2\n",
      "rule.module_list.52.weight   800\n",
      "rule.module_list.52.bias     2\n",
      "rule.module_list.53.weight   800\n",
      "rule.module_list.53.bias     2\n",
      "rule.module_list.54.weight   800\n",
      "rule.module_list.54.bias     2\n",
      "rule.module_list.55.weight   800\n",
      "rule.module_list.55.bias     2\n",
      "rule.module_list.56.weight   800\n",
      "rule.module_list.56.bias     2\n",
      "rule.module_list.57.weight   800\n",
      "rule.module_list.57.bias     2\n",
      "rule.module_list.58.weight   800\n",
      "rule.module_list.58.bias     2\n",
      "rule.module_list.59.weight   800\n",
      "rule.module_list.59.bias     2\n",
      "rule.module_list.60.weight   800\n",
      "rule.module_list.60.bias     2\n",
      "rule.module_list.61.weight   800\n",
      "rule.module_list.61.bias     2\n",
      "rule.module_list.62.weight   800\n",
      "rule.module_list.62.bias     2\n",
      "rule.module_list.63.weight   800\n",
      "rule.module_list.63.bias     2\n",
      "rule.module_list.64.weight   800\n",
      "rule.module_list.64.bias     2\n",
      "rule.module_list.65.weight   800\n",
      "rule.module_list.65.bias     2\n",
      "rule.module_list.66.weight   800\n",
      "rule.module_list.66.bias     2\n",
      "rule.module_list.67.weight   800\n",
      "rule.module_list.67.bias     2\n",
      "rule.module_list.68.weight   800\n",
      "rule.module_list.68.bias     2\n",
      "rule.module_list.69.weight   800\n",
      "rule.module_list.69.bias     2\n",
      "rule.module_list.70.weight   800\n",
      "rule.module_list.70.bias     2\n",
      "rule.module_list.71.weight   800\n",
      "rule.module_list.71.bias     2\n",
      "rule.module_list.72.weight   800\n",
      "rule.module_list.72.bias     2\n",
      "rule.module_list.73.weight   800\n",
      "rule.module_list.73.bias     2\n",
      "rule.module_list.74.weight   800\n",
      "rule.module_list.74.bias     2\n",
      "rule.module_list.75.weight   800\n",
      "rule.module_list.75.bias     2\n",
      "rule.module_list.76.weight   800\n",
      "rule.module_list.76.bias     2\n",
      "rule.module_list.77.weight   800\n",
      "rule.module_list.77.bias     2\n",
      "rule.module_list.78.weight   800\n",
      "rule.module_list.78.bias     2\n",
      "rule.module_list.79.weight   800\n",
      "rule.module_list.79.bias     2\n",
      "rule.module_list.80.weight   800\n",
      "rule.module_list.80.bias     2\n",
      "rule.module_list.81.weight   800\n",
      "rule.module_list.81.bias     2\n",
      "rule.module_list.82.weight   800\n",
      "rule.module_list.82.bias     2\n",
      "rule.module_list.83.weight   800\n",
      "rule.module_list.83.bias     2\n",
      "rule.module_list.84.weight   800\n",
      "rule.module_list.84.bias     2\n",
      "rule.module_list.85.weight   800\n",
      "rule.module_list.85.bias     2\n",
      "rule.module_list.86.weight   800\n",
      "rule.module_list.86.bias     2\n",
      "rule.module_list.87.weight   800\n",
      "rule.module_list.87.bias     2\n",
      "rule.module_list.88.weight   800\n",
      "rule.module_list.88.bias     2\n",
      "rule.module_list.89.weight   800\n",
      "rule.module_list.89.bias     2\n",
      "rule.module_list.90.weight   800\n",
      "rule.module_list.90.bias     2\n",
      "rule.module_list.91.weight   800\n",
      "rule.module_list.91.bias     2\n",
      "rule.module_list.92.weight   800\n",
      "rule.module_list.92.bias     2\n",
      "rule.module_list.93.weight   800\n",
      "rule.module_list.93.bias     2\n",
      "rule.module_list.94.weight   800\n",
      "rule.module_list.94.bias     2\n",
      "rule.module_list.95.weight   800\n",
      "rule.module_list.95.bias     2\n",
      "rule.module_list.96.weight   800\n",
      "rule.module_list.96.bias     2\n",
      "rule.module_list.97.weight   800\n",
      "rule.module_list.97.bias     2\n",
      "rule.module_list.98.weight   800\n",
      "rule.module_list.98.bias     2\n",
      "rule.module_list.99.weight   800\n",
      "rule.module_list.99.bias     2\n",
      "rule.module_list.100.weight   800\n",
      "rule.module_list.100.bias     2\n",
      "rule.module_list.101.weight   800\n",
      "rule.module_list.101.bias     2\n",
      "Total # parameters:  81260\n"
     ]
    }
   ],
   "source": [
    "total_numel = 0\n",
    "for n, p in ca.named_parameters():\n",
    "    print(f'{n:<20} {p.numel():>5}')\n",
    "    total_numel += p.numel()\n",
    "\n",
    "print(f'{\"Total # parameters:\":<20} {total_numel:>5}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def forward_pass(ca, sequences, num_readouts=1):\n",
    "    ridx = np.random.choice(POOL.shape[0], BATCH_SIZE)\n",
    "    state = POOL[ridx, ...].cuda()\n",
    "\n",
    "    # for t in range(warmup_time):\n",
    "    #     readin_patch = ca.rule.readin(torch.zeros(BATCH_SIZE, 1, 1).cuda()).reshape(BATCH_SIZE, READIN_CHANNELS, int(READIN_SCALE*RES), int(READIN_SCALE*RES))\n",
    "    #     readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "    #     state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "    #     state = ca(state)\n",
    "\n",
    "    readin_res = int(READIN_SCALE*RES)\n",
    "    for t in range(timesteps):\n",
    "        readin_patch = ca.rule.readin(sequences[:, [t], 0]).reshape(BATCH_SIZE, READIN_CHANNELS, readin_res, readin_res)\n",
    "        readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "\n",
    "        readin_mask = pad_to(-torch.ones(1, READIN_CHANNELS, RES//2, RES//2), (RES, RES)).cuda() + 1\n",
    "        readin_patch = readin_patch * readin_mask\n",
    "        state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "        state = ca(state)\n",
    "\n",
    "    if np.random.rand() > 0.5:\n",
    "        POOL[ridx] = state.detach().cpu()\n",
    "    else:\n",
    "        POOL[ridx] = ca.seed(RES, BATCH_SIZE)\n",
    "\n",
    "    readout_radius = int(RES*READOUT_SCALE*0.5)\n",
    "    readout_patch = state[:, :READOUT_CHANNELS, RES//2 - readout_radius:RES//2 + readout_radius, RES // 2 - readout_radius:RES // 2 + readout_radius]\n",
    "\n",
    "    # readout_mask_res = readin_res * 2\n",
    "    # mask = torch.ones((1, 1, RES, RES)).cuda() - pad_to(torch.ones((1, 1, readout_mask_res, readout_mask_res)).cuda(), (RES, RES))\n",
    "    # readout_patch = (readout_patch * mask).reshape(BATCH_SIZE, -1)\n",
    "    readout_patch = (readout_patch).reshape(BATCH_SIZE, -1)\n",
    "    # readout_patch = F.max_pool2d(readout_patch, 2).reshape(BATCH_SIZE, -1)\n",
    "    outs = [l_r(readout_patch) for l_r in ca.rule.readouts[:num_readouts]]\n",
    "\n",
    "\n",
    "    return outs\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20, Step: 25/250, Loss: 0.5920, Accuracy: 84.38\n",
      "({N}, accuracy):\n",
      "(2, 84.3750)\n",
      "\n",
      "Epoch: 1/20, Step: 50/250, Loss: 0.0012, Accuracy: 100.00\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "\n",
      "Solved N = 2, starting N = 2 + 1\n",
      "Epoch: 1/20, Step: 75/250, Loss: 0.0790, Accuracy: 100.00\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "\n",
      "Solved N = 3, starting N = 3 + 1\n",
      "Epoch: 1/20, Step: 100/250, Loss: 0.0540, Accuracy: 100.00\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "\n",
      "Solved N = 4, starting N = 4 + 1\n",
      "Epoch: 1/20, Step: 125/250, Loss: 0.0917, Accuracy: 100.00\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "\n",
      "Solved N = 5, starting N = 5 + 1\n",
      "Epoch: 1/20, Step: 150/250, Loss: 0.1080, Accuracy: 99.06\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 95.3125)\n",
      "\n",
      "Epoch: 1/20, Step: 175/250, Loss: 0.0323, Accuracy: 100.00\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "\n",
      "Solved N = 6, starting N = 6 + 1\n",
      "Epoch: 1/20, Step: 200/250, Loss: 0.1298, Accuracy: 99.35\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 96.0938)\n",
      "\n",
      "Epoch: 1/20, Step: 225/250, Loss: 0.0722, Accuracy: 100.00\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "\n",
      "Solved N = 7, starting N = 7 + 1\n",
      "Epoch: 1/20, Step: 250/250, Loss: 0.1733, Accuracy: 99.11\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 98.4375)\n",
      "(8, 95.3125)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:26<08:19, 26.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/20, Step: 25/250, Loss: 0.0602, Accuracy: 99.67\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 99.2188)\n",
      "(8, 98.4375)\n",
      "\n",
      "Solved N = 8, starting N = 8 + 1\n",
      "Epoch: 2/20, Step: 50/250, Loss: 0.2088, Accuracy: 99.12\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 92.9688)\n",
      "\n",
      "Epoch: 2/20, Step: 75/250, Loss: 0.2794, Accuracy: 99.80\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 98.4375)\n",
      "\n",
      "Solved N = 9, starting N = 9 + 1\n",
      "Epoch: 2/20, Step: 100/250, Loss: 0.2351, Accuracy: 99.31\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 99.2188)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 98.4375)\n",
      "(10, 96.0938)\n",
      "\n",
      "Epoch: 2/20, Step: 125/250, Loss: 0.1236, Accuracy: 99.91\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 99.2188)\n",
      "(10, 100.0000)\n",
      "\n",
      "Solved N = 10, starting N = 10 + 1\n",
      "Epoch: 2/20, Step: 150/250, Loss: 0.2236, Accuracy: 99.61\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 99.2188)\n",
      "(10, 99.2188)\n",
      "(11, 97.6562)\n",
      "\n",
      "Epoch: 2/20, Step: 175/250, Loss: 0.1450, Accuracy: 99.84\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 99.2188)\n",
      "(10, 99.2188)\n",
      "(11, 100.0000)\n",
      "\n",
      "Solved N = 11, starting N = 11 + 1\n",
      "Epoch: 2/20, Step: 200/250, Loss: 0.2062, Accuracy: 98.72\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 100.0000)\n",
      "(10, 99.2188)\n",
      "(11, 96.8750)\n",
      "(12, 89.8438)\n",
      "\n",
      "Epoch: 2/20, Step: 225/250, Loss: 0.1223, Accuracy: 99.22\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 100.0000)\n",
      "(10, 100.0000)\n",
      "(11, 95.3125)\n",
      "(12, 96.0938)\n",
      "\n",
      "Epoch: 2/20, Step: 250/250, Loss: 0.0962, Accuracy: 99.79\n",
      "({N}, accuracy):\n",
      "(2, 100.0000)\n",
      "(3, 100.0000)\n",
      "(4, 100.0000)\n",
      "(5, 100.0000)\n",
      "(6, 100.0000)\n",
      "(7, 100.0000)\n",
      "(8, 100.0000)\n",
      "(9, 100.0000)\n",
      "(10, 100.0000)\n",
      "(11, 99.2188)\n",
      "(12, 98.4375)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:11<10:40, 35.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solved N = 12, starting N = 12 + 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "num_training_steps = 250\n",
    "warmup_time = 0\n",
    "optim = torch.optim.Adam(ca.parameters(), lr=1e-2)\n",
    "POOL_SIZE = 1000\n",
    "POOL = ca.seed(RES, POOL_SIZE)\n",
    "\n",
    "# optim = torch.optim.SGD(ca.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "\n",
    "# task details\n",
    "Ns = [2]\n",
    "# Ns = list(np.arange(2, 11))\n",
    "num_extra_heads = 1\n",
    "k_factor = 1\n",
    "min_T = 10 + (Ns[-1]) * k_factor\n",
    "max_T = 10 + min_T + 3*Ns[-1] * k_factor\n",
    "\n",
    "loss_hist = []\n",
    "accuracies =[]\n",
    "print('Training started...')\n",
    "for i_epoch in tqdm(range(num_epochs)):\n",
    "    for i in range(num_training_steps):\n",
    "        optim.zero_grad()\n",
    "\n",
    "        timesteps = np.random.randint(min_T, max_T)\n",
    "        # np.random.randint(timesteps//5, timesteps//3)\n",
    "        # thinking_time = np.random.randint(10, 30)\n",
    "\n",
    "        sequences, labels = make_batch_Nbit_pair_parity(Ns, timesteps, BATCH_SIZE)\n",
    "        sequences = sequences.to(device)\n",
    "        sequences = sequences.repeat_interleave(k_factor, dim=1)\n",
    "        timesteps = sequences.shape[1]\n",
    "        labels = [l.to(device) for l in labels]\n",
    "\n",
    "        outs = forward_pass(ca=ca, sequences=sequences, num_readouts=len(Ns))\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss = 0.\n",
    "        for N_i in range(len(Ns)):\n",
    "            loss += criterion(outs[N_i], labels[N_i])\n",
    "        loss_hist.append(loss.item())\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(ca.parameters(), max_norm=2.0, norm_type=2)  # gradient clipping\n",
    "        optim.step()\n",
    "\n",
    "        # Test and measure accuracy\n",
    "        correct_N = np.zeros_like(Ns)\n",
    "        total = 0\n",
    "        if (i + 1) % 25 == 0:\n",
    "            with torch.no_grad():\n",
    "                timesteps = np.random.randint(min_T, max_T)\n",
    "                # warmup_time = 50\n",
    "                # warmup_time = np.random.randint(timesteps//3, timesteps)\n",
    "                # thinking_time = np.random.randint(10, 30)\n",
    "\n",
    "                sequences, labels = make_batch_Nbit_pair_parity(Ns, timesteps, BATCH_SIZE)\n",
    "                sequences = sequences.to(device)\n",
    "                sequences = sequences.repeat_interleave(k_factor, dim=1)\n",
    "                timesteps = sequences.shape[1]\n",
    "                labels = [l.to(device) for l in labels]\n",
    "\n",
    "                outs = forward_pass(ca=ca, sequences=sequences, num_readouts=len(Ns))\n",
    "\n",
    "                for N_i in range(len(Ns)):\n",
    "                    predicted = torch.max(outs[N_i], 1)[1]\n",
    "\n",
    "                    correct_N[N_i] += (predicted == labels[N_i]).sum()\n",
    "                    total += labels[N_i].size(0)\n",
    "\n",
    "            accuracy = 100 * correct_N / float(total) * len(Ns)\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            print(f'Epoch: {i_epoch+1}/{num_epochs}, Step: {i+1}/{num_training_steps}, '\n",
    "                  f'Loss: {loss_hist[-1]:.4f}, Accuracy: {np.mean(accuracy):.2f}')\n",
    "            print('({N}, accuracy):\\n' + ''.join([f'({Ns[i]}, {accuracy[i]:.4f})\\n' for i in range(len(Ns))]), flush=True)\n",
    "\n",
    "\n",
    "            if np.mean(accuracy) > 98:\n",
    "                if accuracy[-1] > 98:\n",
    "                    if len(Ns) == NUM_READOUT_HEADS:\n",
    "                        break\n",
    "                    print(f'Solved N = {Ns[-1]}, starting N = {Ns[-1]} + {num_extra_heads}')\n",
    "                    Ns += [Ns[-1] + i for i in range(1, num_extra_heads+1)]\n",
    "                    min_T = 10 + (Ns[-1]) * k_factor\n",
    "                    max_T = 10 + min_T + 3*Ns[-1] * k_factor\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Test for longer timescales"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct_N = np.zeros_like(Ns)\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    timesteps = np.random.randint(1000, 2000)\n",
    "    # warmup_time = 50\n",
    "    # warmup_time = np.random.randint(timesteps//3, timesteps)\n",
    "    # thinking_time = np.random.randint(10, 30)\n",
    "\n",
    "    sequences, labels = make_batch_Nbit_pair_parity(Ns, timesteps, BATCH_SIZE)\n",
    "    sequences = sequences.to(device)\n",
    "    sequences = sequences.repeat_interleave(k_factor, dim=1)\n",
    "    timesteps = sequences.shape[1]\n",
    "    labels = [l.to(device) for l in labels]\n",
    "\n",
    "    outs = forward_pass(ca=ca, sequences=sequences, num_readouts=len(Ns))\n",
    "\n",
    "    for N_i in range(len(Ns)):\n",
    "        predicted = torch.max(outs[N_i], 1)[1]\n",
    "\n",
    "        correct_N[N_i] += (predicted == labels[N_i]).sum()\n",
    "        total += labels[N_i].size(0)\n",
    "\n",
    "accuracy = 100 * correct_N / float(total) * len(Ns)\n",
    "accuracies.append(accuracy)\n",
    "\n",
    "print(f'Epoch: {i_epoch+1}/{num_epochs}, Step: {i+1}/{num_training_steps}, '\n",
    "      f'Loss: {loss_hist[-1]:.4f}, Accuracy: {np.mean(accuracy):.2f}')\n",
    "print('({N}, accuracy):\\n' + ''.join([f'({Ns[i]}, {accuracy[i]:.4f})\\n' for i in range(len(Ns))]), flush=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualize in PyGame"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# RES = 200\n",
    "# ca.res = RES"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Heysoos\\AppData\\Local\\Temp\\ipykernel_2700\\3974813681.py:125: RuntimeWarning: invalid value encountered in divide\n",
      "  return (mat - mat.min()) / (mat.max() - mat.min())\n"
     ]
    }
   ],
   "source": [
    "# pygame stuff\n",
    "######################################\n",
    "RESX, RESY = RES, RES\n",
    "state = ca.initGrid(BS=1)\n",
    "\n",
    "pygame.init()\n",
    "size = RESX, RESY\n",
    "\n",
    "win = pygame.display.set_mode((RESX, RESY))\n",
    "\n",
    "screen = pygame.Surface(size)\n",
    "UPSCALE = 20\n",
    "RESXup, RESYup = int(RESX*UPSCALE), int(RESY*UPSCALE)\n",
    "upscaled_screen = pygame.display.set_mode([RESXup, RESYup])\n",
    "FPS_init = 250\n",
    "FPS = int(1*FPS_init)\n",
    "\n",
    "\n",
    "running = True\n",
    "time_ticking = True\n",
    "LMB_trigger = False\n",
    "RMB_trigger = False\n",
    "WHEEL_trigger = False\n",
    "cdim_order = np.arange(0, state.shape[1])\n",
    "\n",
    "do_task = False\n",
    "thinking_time = 0\n",
    "task_ticker = 0\n",
    "t = 0\n",
    "max_readout = 10\n",
    "correct = []\n",
    "\n",
    "clock = pygame.time.Clock()\n",
    "font_h = pygame.font.SysFont(\"Noto Sans\", 24)\n",
    "font = pygame.font.SysFont(\"Noto Sans\", 12)\n",
    "def update_fps(clock, font):\n",
    "    fps = str(int(clock.get_fps()))\n",
    "    fps_text = font.render(fps, 1, pygame.Color(\"white\"))\n",
    "    fps_bg = pygame.Surface((fps_text.get_height(),fps_text.get_width()))  # the size of your rect\n",
    "    fps_bg.set_alpha(50)                # alpha level\n",
    "    fps_bg.fill((255,255,255))           # this fills the entire surface\n",
    "\n",
    "    fps_surf = pygame.Surface((fps_bg.get_height(), fps_bg.get_width()))\n",
    "    fps_surf.blit(fps_bg, (0, 0))\n",
    "    fps_surf.blit(fps_text, (0, 0))\n",
    "    return fps_surf\n",
    "######################################\n",
    "\n",
    "\n",
    "update_rate = 1.\n",
    "ticker = 0.\n",
    "\n",
    "export_imgs = False\n",
    "imgs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    while running:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "            if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                if event.button == 1:\n",
    "                    LMB_trigger = True\n",
    "                if event.button == 3:\n",
    "                    RMB_trigger = True\n",
    "            if event.type == pygame.MOUSEBUTTONUP:\n",
    "                if event.button == 1:\n",
    "                    LMB_trigger = False\n",
    "                if event.button == 3:\n",
    "                    RMB_trigger = False\n",
    "\n",
    "            if event.type == pygame.MOUSEWHEEL:\n",
    "                WHEEL_trigger = True\n",
    "                direction = -event.y\n",
    "\n",
    "            if event.type == pygame.MOUSEBUTTONUP and event.button == 2:\n",
    "                # scroll through channel dims\n",
    "                cdim_order = np.arange(0, state.shape[1])\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_e:\n",
    "                export_imgs = not export_imgs\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_p:\n",
    "                # pause/toggle time\n",
    "                time_ticking = not time_ticking\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_s:\n",
    "                # start a task\n",
    "                do_task = not do_task\n",
    "                if not do_task:\n",
    "                    FPS = 120\n",
    "                task_ticker = 0\n",
    "                timesteps = 1_000\n",
    "\n",
    "                sequence = generate_binary_sequence(timesteps)\n",
    "                sequence = sequence.to(device)\n",
    "                labels = [torch.stack([get_parity(sequence[ii - N:ii], N) for ii in range(N, len(sequence))]) for N in Ns]\n",
    "                labels = [l.to(device) for l in labels]\n",
    "                sequence = sequence.repeat_interleave(k_factor)\n",
    "                labels = [l.repeat_interleave(k_factor) for l in labels]\n",
    "                timesteps = len(sequence)\n",
    "\n",
    "                correct_N = []\n",
    "\n",
    "                # state = ca.initGrid(BS=1)\n",
    "\n",
    "                ridx = np.random.choice(POOL.shape[0])\n",
    "                state = POOL[[ridx], ...].cuda()\n",
    "\n",
    "\n",
    "            if event.type == pygame.KEYDOWN and event.key == pygame.K_r:\n",
    "                # start from seed\n",
    "                state = ca.initGrid(BS=1)\n",
    "\n",
    "        mouse_pos = pygame.mouse.get_pos()\n",
    "        if LMB_trigger:\n",
    "            state = LMB_make(state, r=r, s=s)\n",
    "        if RMB_trigger:\n",
    "            state = RMB_del(state, r=r, s=s)\n",
    "\n",
    "        if WHEEL_trigger:\n",
    "            cdim_order = WHEEL_permute(cdim_order, direction)\n",
    "            WHEEL_trigger = False\n",
    "\n",
    "        # nx = state[0, cdim_order[0], :, :].cpu().numpy()\n",
    "        nx = min_max(state[0, cdim_order[0:3], :, :].cpu().numpy().transpose(1, 2, 0))\n",
    "        # nx = min_max(state[0, :, :, :].mean(dim=0).cpu().numpy())\n",
    "        nx = nx * 255.\n",
    "\n",
    "        if time_ticking:\n",
    "\n",
    "            if do_task:\n",
    "                if task_ticker < (timesteps + warmup_time) and task_ticker < timesteps - Ns[-1]*k_factor - 1:\n",
    "                    if task_ticker > warmup_time:\n",
    "                        t = task_ticker - warmup_time\n",
    "\n",
    "                        readin_res = int(READIN_SCALE*RES)\n",
    "                        readin_patch = ca.rule.readin(sequence[t].unsqueeze(0)).reshape(1, READIN_CHANNELS, readin_res, readin_res)\n",
    "                        readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "\n",
    "                        readin_mask = pad_to(-torch.ones(1, READIN_CHANNELS, RES//2, RES//2), (RES, RES)).cuda() + 1\n",
    "                        readin_patch = readin_patch * readin_mask\n",
    "                        state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "\n",
    "\n",
    "                        # readin_res = int(READIN_SCALE*RES)\n",
    "                        # readin_patch = ca.rule.readin(sequence[t].unsqueeze(0)).reshape(1, READIN_CHANNELS, readin_res, readin_res)\n",
    "                        # readin_patch = pad_to(readin_patch, (RES, RES))\n",
    "                        # state[:, -READIN_CHANNELS:, ...] = state[:, -READIN_CHANNELS:, ...] + readin_patch\n",
    "                    task_ticker += 1\n",
    "                else:\n",
    "                    do_task = False\n",
    "                    t = 0\n",
    "\n",
    "            state = ca.forward(state)\n",
    "            ticker += 1\n",
    "            # if do_task:\n",
    "                # readout_patch = state[...,center-r:center+r+1, center-r:center+r+1].reshape(BATCH_SIZE, -1)\n",
    "                # out = ca.rule.readout(readout_patch)\n",
    "\n",
    "            if export_imgs:\n",
    "                imgs.append(nx)\n",
    "\n",
    "        pygame.surfarray.blit_array(screen, nx)\n",
    "        frame = pygame.transform.scale(screen, (RESXup, RESYup))\n",
    "\n",
    "        upscaled_screen.blit(frame, frame.get_rect())\n",
    "        upscaled_screen.blit(update_fps(clock, font), (10,0))\n",
    "        if do_task:\n",
    "            minimum_wait_time = t - Ns[-1]*k_factor - thinking_time + 1\n",
    "\n",
    "            if minimum_wait_time >= 0 and minimum_wait_time % k_factor == 0: # only do readout on the end of the time-dilation to be the same as training\n",
    "                FPS=10\n",
    "                # readout_patch = state[:, :READOUT_CHANNELS, ...]\n",
    "                # mask = torch.ones((1, 1, RES, RES)).cuda() - pad_to(torch.ones((1, 1, readin_res, readin_res)).cuda(), (RES, RES))\n",
    "                # readout_patch = (readout_patch * mask).reshape(1, -1)\n",
    "\n",
    "                readout_radius = int(RES*READOUT_SCALE*0.5)\n",
    "                readout_patch = state[:, :READOUT_CHANNELS, RES//2 - readout_radius:RES//2 + readout_radius, RES // 2 - readout_radius:RES // 2 + readout_radius]\n",
    "                readout_patch = (readout_patch).reshape(1, -1)\n",
    "\n",
    "                outs = [l_r(readout_patch) for l_r in ca.rule.readouts[:len(Ns)]]\n",
    "\n",
    "                # each task N has labels if different length that are indexed differently.\n",
    "                t_label_N = [t - N*k_factor - thinking_time + 1 for N in Ns]\n",
    "                # used for the histograms\n",
    "                label_t = torch.stack([l[t_label_N[il]].cpu() for il, l in enumerate(labels[:max_readout])]).numpy()\n",
    "\n",
    "                correct_N = []\n",
    "                for N_i in range(len(Ns)):\n",
    "                    predicted = torch.max(outs[N_i], 1)[1][0]\n",
    "                    correct_N.append((predicted == labels[N_i][t_label_N[N_i]]).sum().cpu().numpy())\n",
    "\n",
    "                if len(correct) < 1000:\n",
    "                    correct.append(correct_N)\n",
    "                else:\n",
    "                    correct = [correct_N] + correct[1:]\n",
    "\n",
    "            if minimum_wait_time >= 0:\n",
    "                # plot the histograms\n",
    "                graph_surf = plot_classification_scores(\n",
    "                    F.softmax(\n",
    "                        torch.stack(outs)[:max_readout, ...].squeeze(1).cpu(), dim=1\n",
    "                    ).numpy(), label_t, width=RESXup//6, height=int(len(label_t) * RESYup//10))\n",
    "                upscaled_screen.blit(graph_surf, (0,30))\n",
    "                upscaled_screen.blit(print_something(100 * np.mean(correct)), (10,20))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        clock.tick(FPS)\n",
    "\n",
    "pygame.quit()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.hist(state.reshape(-1).cpu().numpy(), 100); plt.yscale('log')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
